{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nkikn/Facial-Expression-Recognition/blob/main/facial_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jW-rHdUjyitF",
        "outputId": "eeb47405-897d-403e-f3e0-d8a7d4a5f090"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.4.26)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install wandb torch torchvision pandas numpy matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtZdXIgT0CNt",
        "outputId": "05acdefe-fe1c-413e-c45b-838cb51af9a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "KuZvReFo0EJu"
      },
      "outputs": [],
      "source": [
        "# Upload your kaggle.json to Colab and run:\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/ColabNotebooks/kaggle_API_credentials/kaggle.json ~/.kaggle/kaggle.json\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F_yoEma1LRq",
        "outputId": "9e7f2bac-b7f3-46da-c9a6-b2c6c62c0650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "challenges-in-representation-learning-facial-expression-recognition-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "replace example_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset\n",
        "!kaggle competitions download -c challenges-in-representation-learning-facial-expression-recognition-challenge\n",
        "!unzip -q challenges-in-representation-learning-facial-expression-recognition-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Sda2Y8vD1Odt"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import torch.nn.functional as F\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import torchvision.transforms as transforms\n",
        "# from sklearn.metrics import classification_report, confusion_matrix\n",
        "# import wandb\n",
        "# import time\n",
        "# from datetime import datetime\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TOhpunledmGI"
      },
      "outputs": [],
      "source": [
        "# Facial Expression Recognition - Simple CNN Baseline\n",
        "# Notebook 1: Simple CNN Architecture\n",
        "\n",
        "# Cell 1: Setup and Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import wandb\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "PeIFlByy4v86",
        "outputId": "8d6a8fbd-15af-401c-b7f1-d2b0f0f4f614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250605_173723-3mtiyypo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition/runs/3mtiyypo' target=\"_blank\">test_overfit</a></strong> to <a href='https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition/runs/3mtiyypo' target=\"_blank\">https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition/runs/3mtiyypo</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Cell 2: Wandb Setup\n",
        "# Initialize Wandb\n",
        "wandb.login()\n",
        "\n",
        "# Wandb configuration\n",
        "config = {\n",
        "    'model_name': 'test_overfit',\n",
        "    'learning_rate': 0.001,\n",
        "    'batch_size': 128,\n",
        "    'epochs': 20,\n",
        "    'optimizer': 'Adam',\n",
        "    'loss_function': 'CrossEntropyLoss',\n",
        "}\n",
        "\n",
        "# Initialize wandb run\n",
        "run = wandb.init(\n",
        "    project=\"facial-expression-recognition\",\n",
        "    name=\"test_overfit\",\n",
        "    config=config,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKRjJCZZ4v87",
        "outputId": "dfb8cd10-3f89-4781-a5d5-9c0b9c2dc94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 28709\n",
            "Validation samples: 28709\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class My_Set(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pixels = self.data.iloc[idx]['pixels']\n",
        "        image = np.array([int(x) for x in pixels.split()]).reshape(48, 48)\n",
        "        image = Image.fromarray(image.astype(np.uint8), mode='L')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.data.iloc[idx]['emotion']\n",
        "        return image, label\n",
        "\n",
        "\n",
        "# Define transforms\n",
        "transform = transforms.Compose([\n",
        "    # transforms.ToPILImage(),\n",
        "    transforms.Resize((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "train_indices, val_indices = train_test_split(\n",
        "    range(len(train_df)),\n",
        "    test_size=0.2,\n",
        "    stratify=train_df['emotion'],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = My_Set(train_df, transform)\n",
        "val_dataset = My_Set(train_df, transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    # sampler=sampler\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config['batch_size'],\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_dataset)}\")\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "x9e9E1RD4v87"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "\n",
        "        # First conv layer: input 1 channel, output 32 channels\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # 1x48x48 -> 32x48x48\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Halve spatial size\n",
        "\n",
        "        # Second conv layer: input 32 channels, output 64 channels\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # 32x24x24 -> 64x24x24\n",
        "\n",
        "        # After 2 poolings, spatial size 48 -> 24 -> 12\n",
        "        # So flatten dimension = 64 * 12 * 12\n",
        "        self.fc1 = nn.Linear(64 * 12 * 12, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(x)  # 48 -> 24\n",
        "\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.pool(x)  # 24 -> 12\n",
        "\n",
        "        x = x.view(-1, 64 * 12 * 12)  # Flatten\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfew0Qfo4v88",
        "outputId": "bed5386e-a681-4c62-cd08-786676f9de1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total parameters: 1,199,495\n",
            "Trainable parameters: 1,199,495\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize model\n",
        "model = SimpleCNN().to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "0UJ2bJd54v88"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Log model info to wandb\n",
        "wandb.log({\"total_parameters\": total_params, \"trainable_parameters\": trainable_params})\n",
        "\n",
        "# Cell 5: Training Setup\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "lr-j_1Ha4v88"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 6: Training Functions\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=\"Training\")\n",
        "    for inputs, labels in pbar:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{running_loss/len(train_loader):.4f}',\n",
        "            'Acc': f'{100*correct/total:.2f}%'\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Validation function\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "\n",
        "    return epoch_loss, epoch_acc, all_preds, all_targets"
      ],
      "metadata": {
        "id": "bu84dN3dAW_h"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BVgogFJn4v89"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 7: Training Loop\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Training phase\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "\n",
        "        # Validation phase\n",
        "        val_loss, val_acc, val_predictions, val_labels = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate epoch time\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        # Store metrics\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        # Log to wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"train_accuracy\": train_acc,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_accuracy\": val_acc,\n",
        "            \"learning_rate\": optimizer.param_groups[0]['lr'],\n",
        "            \"epoch_time\": epoch_time\n",
        "        })\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_simple_cnn.pth')\n",
        "            wandb.log({\"best_val_accuracy\": best_val_acc})\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"Epoch Time: {epoch_time:.2f}s\")\n",
        "\n",
        "        # Early stopping check (optional)\n",
        "        if epoch > 20 and val_acc < best_val_acc - 5:  # Stop if val acc drops by 5%\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies, val_predictions, val_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ETTRlHt4v89",
        "outputId": "1cced7ee-343d-46bc-ca72-e73d696cb7df"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "\n",
            "Epoch 1/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.91it/s, Loss=1.6765, Acc=33.25%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.6765, Train Acc: 33.25%\n",
            "Val Loss: 1.5542, Val Acc: 40.35%\n",
            "Epoch Time: 55.09s\n",
            "\n",
            "Epoch 2/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.74it/s, Loss=1.4788, Acc=43.14%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.4788, Train Acc: 43.14%\n",
            "Val Loss: 1.4122, Val Acc: 45.45%\n",
            "Epoch Time: 53.12s\n",
            "\n",
            "Epoch 3/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.97it/s, Loss=1.3473, Acc=48.20%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3473, Train Acc: 48.20%\n",
            "Val Loss: 1.2753, Val Acc: 50.96%\n",
            "Epoch Time: 56.28s\n",
            "\n",
            "Epoch 4/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:29<00:00, 15.08it/s, Loss=1.2659, Acc=51.68%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.2659, Train Acc: 51.68%\n",
            "Val Loss: 1.1787, Val Acc: 55.26%\n",
            "Epoch Time: 54.67s\n",
            "\n",
            "Epoch 5/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.32it/s, Loss=1.1971, Acc=54.63%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1971, Train Acc: 54.63%\n",
            "Val Loss: 1.1365, Val Acc: 58.25%\n",
            "Epoch Time: 53.65s\n",
            "\n",
            "Epoch 6/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.90it/s, Loss=1.1296, Acc=57.59%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.1296, Train Acc: 57.59%\n",
            "Val Loss: 1.0359, Val Acc: 61.67%\n",
            "Epoch Time: 52.37s\n",
            "\n",
            "Epoch 7/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.09it/s, Loss=1.0628, Acc=60.57%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.0628, Train Acc: 60.57%\n",
            "Val Loss: 0.9704, Val Acc: 64.55%\n",
            "Epoch Time: 53.73s\n",
            "\n",
            "Epoch 8/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.92it/s, Loss=0.9920, Acc=63.52%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9920, Train Acc: 63.52%\n",
            "Val Loss: 0.9051, Val Acc: 67.16%\n",
            "Epoch Time: 52.05s\n",
            "\n",
            "Epoch 9/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.97it/s, Loss=0.9275, Acc=65.93%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.9275, Train Acc: 65.93%\n",
            "Val Loss: 0.8466, Val Acc: 69.82%\n",
            "Epoch Time: 53.91s\n",
            "\n",
            "Epoch 10/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:26<00:00, 16.63it/s, Loss=0.8521, Acc=68.89%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.8521, Train Acc: 68.89%\n",
            "Val Loss: 0.7346, Val Acc: 74.76%\n",
            "Epoch Time: 51.52s\n",
            "\n",
            "Epoch 11/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.12it/s, Loss=0.7803, Acc=71.73%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7803, Train Acc: 71.73%\n",
            "Val Loss: 0.6704, Val Acc: 77.11%\n",
            "Epoch Time: 53.12s\n",
            "\n",
            "Epoch 12/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:25<00:00, 17.31it/s, Loss=0.7003, Acc=74.88%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.7003, Train Acc: 74.88%\n",
            "Val Loss: 0.6038, Val Acc: 79.30%\n",
            "Epoch Time: 51.61s\n",
            "\n",
            "Epoch 13/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.96it/s, Loss=0.6200, Acc=78.33%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6200, Train Acc: 78.33%\n",
            "Val Loss: 0.4972, Val Acc: 83.56%\n",
            "Epoch Time: 51.94s\n",
            "\n",
            "Epoch 14/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.15it/s, Loss=0.5440, Acc=81.04%]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.5440, Train Acc: 81.04%\n",
            "Val Loss: 0.4415, Val Acc: 85.22%\n",
            "Epoch Time: 53.52s\n",
            "\n",
            "Epoch 15/30\n",
            "----------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.17it/s, Loss=0.4759, Acc=83.30%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.4759, Train Acc: 83.30%\n",
            "Val Loss: 0.3855, Val Acc: 88.04%\n",
            "Epoch Time: 51.27s\n",
            "\n",
            "Epoch 16/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.96it/s, Loss=0.3229, Acc=90.58%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.3229, Train Acc: 90.58%\n",
            "Val Loss: 0.2932, Val Acc: 91.76%\n",
            "Epoch Time: 53.75s\n",
            "\n",
            "Epoch 17/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:26<00:00, 16.68it/s, Loss=0.2949, Acc=91.63%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2949, Train Acc: 91.63%\n",
            "Val Loss: 0.2760, Val Acc: 92.37%\n",
            "Epoch Time: 51.69s\n",
            "\n",
            "Epoch 18/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.10it/s, Loss=0.2807, Acc=92.01%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2807, Train Acc: 92.01%\n",
            "Val Loss: 0.2629, Val Acc: 93.09%\n",
            "Epoch Time: 52.53s\n",
            "\n",
            "Epoch 19/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:26<00:00, 16.89it/s, Loss=0.2681, Acc=92.61%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2681, Train Acc: 92.61%\n",
            "Val Loss: 0.2504, Val Acc: 93.41%\n",
            "Epoch Time: 52.25s\n",
            "\n",
            "Epoch 20/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.87it/s, Loss=0.2571, Acc=92.97%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2571, Train Acc: 92.97%\n",
            "Val Loss: 0.2398, Val Acc: 93.67%\n",
            "Epoch Time: 51.78s\n",
            "\n",
            "Epoch 21/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.07it/s, Loss=0.2462, Acc=93.34%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2462, Train Acc: 93.34%\n",
            "Val Loss: 0.2317, Val Acc: 93.90%\n",
            "Epoch Time: 53.55s\n",
            "\n",
            "Epoch 22/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.56it/s, Loss=0.2360, Acc=93.67%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2360, Train Acc: 93.67%\n",
            "Val Loss: 0.2189, Val Acc: 94.52%\n",
            "Epoch Time: 51.21s\n",
            "\n",
            "Epoch 23/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 16.02it/s, Loss=0.2264, Acc=93.98%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2264, Train Acc: 93.98%\n",
            "Val Loss: 0.2111, Val Acc: 94.67%\n",
            "Epoch Time: 53.29s\n",
            "\n",
            "Epoch 24/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:26<00:00, 17.22it/s, Loss=0.2168, Acc=94.37%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2168, Train Acc: 94.37%\n",
            "Val Loss: 0.2045, Val Acc: 94.98%\n",
            "Epoch Time: 51.67s\n",
            "\n",
            "Epoch 25/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.93it/s, Loss=0.2078, Acc=94.81%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2078, Train Acc: 94.81%\n",
            "Val Loss: 0.1926, Val Acc: 95.37%\n",
            "Epoch Time: 52.02s\n",
            "\n",
            "Epoch 26/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 15.98it/s, Loss=0.1989, Acc=94.99%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1989, Train Acc: 94.99%\n",
            "Val Loss: 0.1836, Val Acc: 95.83%\n",
            "Epoch Time: 53.86s\n",
            "\n",
            "Epoch 27/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.25it/s, Loss=0.1905, Acc=95.30%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1905, Train Acc: 95.30%\n",
            "Val Loss: 0.1752, Val Acc: 96.06%\n",
            "Epoch Time: 51.37s\n",
            "\n",
            "Epoch 28/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:27<00:00, 16.12it/s, Loss=0.1819, Acc=95.69%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1819, Train Acc: 95.69%\n",
            "Val Loss: 0.1680, Val Acc: 96.20%\n",
            "Epoch Time: 52.88s\n",
            "\n",
            "Epoch 29/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:26<00:00, 17.16it/s, Loss=0.1742, Acc=95.93%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1742, Train Acc: 95.93%\n",
            "Val Loss: 0.1600, Val Acc: 96.56%\n",
            "Epoch Time: 51.71s\n",
            "\n",
            "Epoch 30/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 449/449 [00:28<00:00, 16.03it/s, Loss=0.1662, Acc=96.15%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.1662, Train Acc: 96.15%\n",
            "Val Loss: 0.1517, Val Acc: 96.75%\n",
            "Epoch Time: 51.38s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cell 8: Train Model\n",
        "print(\"Starting training...\")\n",
        "train_losses, train_accs, val_losses, val_accs, final_predictions, final_labels = train_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, scheduler, config['epochs']\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vugE5Zha4v89"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 9: Results Analysis and Visualization\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_accs, label='Train Accuracy')\n",
        "plt.plot(val_accs, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcFP7FSv4v89"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Confusion Matrix\n",
        "plt.subplot(1, 3, 3)\n",
        "class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "cm = confusion_matrix(final_labels, final_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('simple_cnn_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNFZnM9X4v8-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Log plots to wandb\n",
        "wandb.log({\"training_curves\": wandb.Image(plt)})\n",
        "\n",
        "# Cell 10: Detailed Performance Analysis\n",
        "# Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(final_labels, final_predictions, target_names=class_names))\n",
        "\n",
        "# Calculate per-class accuracy\n",
        "class_accuracies = {}\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_mask = np.array(final_labels) == i\n",
        "    if np.sum(class_mask) > 0:\n",
        "        class_acc = np.sum(np.array(final_predictions)[class_mask] == i) / np.sum(class_mask)\n",
        "        class_accuracies[class_name] = class_acc * 100\n",
        "\n",
        "print(\"\\nPer-class Accuracies:\")\n",
        "for class_name, acc in class_accuracies.items():\n",
        "    print(f\"{class_name}: {acc:.2f}%\")\n",
        "\n",
        "# Log final metrics to wandb\n",
        "final_metrics = {\n",
        "    \"final_train_accuracy\": train_accs[-1],\n",
        "    \"final_val_accuracy\": val_accs[-1],\n",
        "    \"best_val_accuracy\": max(val_accs),\n",
        "    \"final_train_loss\": train_losses[-1],\n",
        "    \"final_val_loss\": val_losses[-1],\n",
        "}\n",
        "\n",
        "# Add per-class accuracies\n",
        "for class_name, acc in class_accuracies.items():\n",
        "    final_metrics[f\"class_accuracy_{class_name.lower()}\"] = acc\n",
        "\n",
        "wandb.log(final_metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvFLUHtg4v8-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # Cell 11: Model Summary and Insights\n",
        "# print(\"\\n\" + \"=\"*50)\n",
        "# print(\"SIMPLE CNN MODEL SUMMARY\")\n",
        "# print(\"=\"*50)\n",
        "# print(f\"Architecture: {config['architecture']}\")\n",
        "# print(f\"Total Parameters: {total_params:,}\")\n",
        "# print(f\"Best Validation Accuracy: {max(val_accs):.2f}%\")\n",
        "# print(f\"Final Validation Accuracy: {val_accs[-1]:.2f}%\")\n",
        "# print(f\"Training Time: {len(train_accs)} epochs\")\n",
        "\n",
        "# print(\"\\nKey Observations:\")\n",
        "# print(\"1. Simple architecture with only 2 conv layers\")\n",
        "# print(\"2. No regularization techniques applied\")\n",
        "# print(\"3. Basic architecture serves as baseline\")\n",
        "# print(\"4. Limited capacity may cause underfitting\")\n",
        "# print(\"5. Good starting point for progressive development\")\n",
        "\n",
        "# print(\"\\nNext Steps:\")\n",
        "# print(\"1. Increase model depth (more conv layers)\")\n",
        "# print(\"2. Add regularization (BatchNorm, Dropout)\")\n",
        "# print(\"3. Experiment with different architectures\")\n",
        "# print(\"4. Apply data augmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ME15Ns1U4v8-"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Cell 12: Save Model and Artifacts\n",
        "# Save final model\n",
        "torch.save(model.state_dict(), 'test_overfit.pth')\n",
        "\n",
        "# Save model artifact to wandb\n",
        "artifact = wandb.Artifact('simple_cnn_model', type='model')\n",
        "artifact.add_file('test_overfit.pth')\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "# Save training history\n",
        "import pickle\n",
        "history = {\n",
        "    'train_losses': train_losses,\n",
        "    'train_accuracies': train_accs,\n",
        "    'val_losses': val_losses,\n",
        "    'val_accuracies': val_accs,\n",
        "    'config': config,\n",
        "    'final_predictions': final_predictions,\n",
        "    'final_labels': final_labels\n",
        "}\n",
        "\n",
        "\n",
        "with open('test_overfit_history.pkl', 'wb') as f:\n",
        "    pickle.dump(history, f)\n",
        "\n",
        "# Finish wandb run\n",
        "wandb.finish()\n",
        "\n",
        "print(\"\\nTraining completed and logged to Wandb!\")\n",
        "print(\"Model saved as 'test_overfit.pth'\")\n",
        "print(\"Training history saved as 'test_overfit_history.pkl'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overfit_test**"
      ],
      "metadata": {
        "id": "lV8Mdo3LHfm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "OrPvOCv_G8Eq",
        "outputId": "675064de-7453-43a1-de21-2d3be9b2a8ef"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>▃▅▆▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch_time</td><td>▁▁▁█████▇█▇█▇█▇▇█▇█▇▇▇▇█▇█▇▇█▇▇▇▇</td></tr><tr><td>learning_rate</td><td>█████████████████▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>total_parameters</td><td>▁▁▁</td></tr><tr><td>train_accuracy</td><td>▄▅▆▁▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>▃▃▃█▇▆▆▆▅▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainable_parameters</td><td>▁▁▁</td></tr><tr><td>val_accuracy</td><td>▃▅▆▁▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇▇█████████████</td></tr><tr><td>val_loss</td><td>▄▃▂█▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_accuracy</td><td>96.74666</td></tr><tr><td>epoch</td><td>30</td></tr><tr><td>epoch_time</td><td>51.37519</td></tr><tr><td>learning_rate</td><td>1e-05</td></tr><tr><td>total_parameters</td><td>1199495</td></tr><tr><td>train_accuracy</td><td>96.15452</td></tr><tr><td>train_loss</td><td>0.16617</td></tr><tr><td>trainable_parameters</td><td>1199495</td></tr><tr><td>val_accuracy</td><td>96.74666</td></tr><tr><td>val_loss</td><td>0.15172</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">test_overfit</strong> at: <a href='https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition/runs/3mtiyypo' target=\"_blank\">https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition/runs/3mtiyypo</a><br> View project at: <a href='https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition' target=\"_blank\">https://wandb.ai/nkikn21-free-university-of-tbilisi-/facial-expression-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250605_173723-3mtiyypo/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PgNjS88G8ga"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}